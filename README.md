# Representation
Time: 10:00 am, Wednesday

Venue: JS401

Welcome to QFNU-NLPer Seminar 2025 Spring

# On Papers
Please choose recent papers (2025, 2024, 2023, 2022, 2021) from top NLP/AI venues. A (incomplete) list is

NLP: ACL, TACL, EMNLP, NAACL, EACL, COLING

ML: ICML, NeurIPS, AISTATS, JMLR, ICLR, ICDE

AI: AAAI, IJCAI, CVPR

IR/DM: SIGIR, CIKM, WSDM, KDD, WWW, ICDM

While we are interested in a broad range of NLP/AI topics, the followings (and a list here) are of great importance

syntactic/semantic parsing

entity/relation/event extraction

distributed/distributional/compositional semantics

MT/MRC/QA/Dialog

knowledge analysis and processing

(deep) learning algorithms

Materials with broad interests are welcome (e.g., tutorials form top conferences, high-quality surveys).

# For Presenters
Please fill your slots in the Agenda at least one week before your presentation.

Please format Paper fields with [venue+year]title (e.g. [ACL19]A Good Paper).

Please upload your slides, and add links to them in Slides fields.

Besides technical novelties, please give enough background knowledge in case people are unfamiliar with your topic.

It would be great to keep your presentation within 50 min.

# For Audiences
Please read abstract/introduction sections before the seminar.




# Reports

| Week | Date | Speaker | Paper | Materials |
| ---- | ---- | ------- | ----- | --------- |
| 1-3 | 2.19 2.26 3.5 | 吕瑞森 | [\[1\]Better & Faster Large Language Models via Multi-token Prediction](https://github.com/NLPcourse/report/blob/main/Week1-3/Better%20%26%20Faster%20Large%20Language%20Models%20via%20Multi-token%20Prediction.pdf) <br> [\[2\]DeepSeek-V3 Technical Report](https://github.com/NLPcourse/report/blob/main/Week1-3/DeepSeek-V3%20Technical%20Report.pdf) <br> [\[3\]EAGLE Speculative Sampling Requires Rethinking Feature Uncertainty](https://github.com/NLPcourse/report/blob/main/Week1-3/EAGLE%20Speculative%20Sampling%20Requires%20Rethinking%20Feature%20Uncertainty.pdf) <br> [\[4\]Fast Inference from Transformers via Speculative Decoding](https://github.com/NLPcourse/report/blob/main/Week1-3/Fast%20Inference%20from%20Transformers%20via%20Speculative%20Decoding.pdf) <br> [\[5\]GShard Scaling Giant Models with Conditional Computation and Automatic Sharding](https://github.com/NLPcourse/report/blob/main/Week1-3/GShard%20Scaling%20Giant%20Models%20with%20Conditional%20Computation%20and%20Automatic%20Sharding.pdf) <br> [\[6\]Switch Transformers Scaling to Trillion Parameter Models with Simple and Efficient Sparsity](https://github.com/NLPcourse/report/blob/main/Week1-3/Switch%20Transformers%20Scaling%20to%20Trillion%20Parameter%20Models%20with%20Simple%20and%20Efficient%20Sparsity.pdf)| [slide](https://github.com/NLPcourse/report/blob/main/Week1-3/DeepSeek-v3.pptx) |
| 4-6 | 3.12 3.19 3.26 | 吕瑞森 | [\[1\]Chain-of-Thought Prompting Elicits Reasoningin Large Language Models](https://github.com/NLPcourse/report/blob/main/Week4-6/Chain-of-Thought%20Prompting%20Elicits%20Reasoningin%20Large%20Language%20Models.pdf) <br> [\[2\]Challenging BIG-Bench tasks andwhether chain-of-thought can solve them](https://github.com/NLPcourse/report/blob/main/Week4-6/Challenging%20BIG-Bench%20tasks%20andwhether%20chain-of-thought%20can%20solve%20them.pdf) <br> [\[3\]DeepSeek R1 Incentivizing Reasoning Capability in LLMs via](https://github.com/NLPcourse/report/blob/main/Week4-6/DeepSeek%20R1%20Incentivizing%20Reasoning%20Capability%20in%20LLMs%20via.pdf) <br> [\[4\]DeepSeekMath Pushing the Limits of Mathematical Reasoning in Open Language Models](https://github.com/NLPcourse/report/blob/main/Week4-6/DeepSeekMath%20Pushing%20the%20Limits%20of%20Mathematical%20Reasoning%20in%20Open%20Language%20Models.pdf) <br> [\[5\]How Far Are We From AGl Are LLMs All We Need](https://github.com/NLPcourse/report/blob/main/Week4-6/How%20Far%20Are%20We%20From%20AGl%20Are%20LLMs%20All%20We%20Need.pdf) <br> [\[6\]Large Language Models Can Self-Improve in Long-context Reasoning](https://github.com/NLPcourse/report/blob/main/Week4-6/Large%20Language%20Models%20Can%20Self-Improve%20in%20Long-context%20Reasoning.pdf) <br> [\[7\]Large Language Models are Zero-Shot Reasoners](https://github.com/NLPcourse/report/blob/main/Week4-6/Large%20Language%20Models%20are%20Zero-Shot%20Reasoners.pdf) <br> [\[8\]Let's Verify Step by Step](https://github.com/NLPcourse/report/blob/main/Week4-6/Let's%20Verify%20Step%20by%20Step.pdf) <br> [\[9\]Levels of AGI for Operationalizing Progress on the Path to AGI](https://github.com/NLPcourse/report/blob/main/Week4-6/Levels%20of%20AGI%20for%20Operationalizing%20Progress%20on%20the%20Path%20to%20AGI.pdf) <br> [\[10\]Mastering the game of Go without human knowledge](https://github.com/NLPcourse/report/blob/main/Week4-6/Mastering%20the%20game%20of%20Go%20without%20human%20knowledge.pdf) <br> [\[11\]Math-Shepherd Verify and Reinforce LLMs Step-by-step without Human Annotations](https://github.com/NLPcourse/report/blob/main/Week4-6/Math-Shepherd%20Verify%20and%20Reinforce%20LLMs%20Step-by-step%20without%20Human%20Annotations.pdf) <br> [\[12\]Program of Thoughts Prompting Disentangling Computation from Reasoning for Numerical Reasoning Tasks.](https://github.com/NLPcourse/report/blob/main/Week4-6/Program%20of%20Thoughts%20Prompting%20Disentangling%20Computation%20from%20Reasoning%20for%20Numerical%20Reasoning%20Tasks.pdf) <br> [\[13\]SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHTREASONING IN LANGUAGE MODELS](https://github.com/NLPcourse/report/blob/main/Week4-6/SELF-CONSISTENCY%20IMPROVES%20CHAIN%20OF%20THOUGHTREASONING%20IN%20LANGUAGE%20MODELS.pdf) <br> [\[14\]SFT Memorizes, RL Generalizes A Comparative Study of Foundation Model Post-training](https://github.com/NLPcourse/report/blob/main/Week4-6/SFT%20Memorizes%2C%20RL%20Generalizes%20A%20Comparative%20Study%20of%20Foundation%20Model%20Post-training.pdf) <br> [\[15\]Scaling of Search and Learning A Roadmap to Reproduce o1 from Reinforcement Learning Perspective](https://github.com/NLPcourse/report/blob/main/Week4-6/Scaling%20of%20Search%20and%20Learning%20A%20Roadmap%20to%20Reproduce%20o1%20from%20Reinforcement%20Learning%20Perspective.pdf) <br> [\[16\]Solving math word problems with process- and outcome-based feedback](https://github.com/NLPcourse/report/blob/main/Week4-6/Solving%20math%20word%20problems%20with%20process-%20and%20outcome-based%20feedback.pdf) <br> [\[17\]Training Verifers to Solve Math Word Problems](https://github.com/NLPcourse/report/blob/main/Week4-6/Training%20Verifers%20to%20Solve%20Math%20Word%20Problems.pdf) | [slide](https://github.com/NLPcourse/report/blob/main/Week4-6/DeepSeek-R1.pptx) |
| 7 | 4.2 | 吕瑞森 | [\[1\]GAIA A Benchmark for General AI A ssistants](https://github.com/NLPcourse/report/blob/main/Week7/GAIA%20A%20Benchmark%20for%20General%20AI%20A%20ssistants.pdf) <br> [\[2\]REACT SYNERGIZING REASONING AND ACTING INREACT LANGUAGE MODELS](https://github.com/NLPcourse/report/blob/main/Week7/REACT%20SYNERGIZING%20REASONING%20AND%20ACTING%20INREACT%20LANGUAGE%20MODELS.pdf) <br> [\[3\]Toolformer Language Models Can Teach Themselves to Use Tools](https://github.com/NLPcourse/report/blob/main/Week7/Toolformer%20Language%20Models%20Can%20Teach%20Themselves%20to%20Use%20Tools.pdf) | [slide](https://github.com/NLPcourse/report/blob/main/Week7/AI%20agent.pptx)|
| 8-10 | 4.9 4.16 4.23 | complete project for goverment |  |  |
| 11 | 4.30 | leave |  |  |
| 12 | 5.7 | complete project for goverment | | |
| 13 | 5.14 | 吕瑞森 | [\[1\]AI models collapse when trained on recursively generated data](https://github.com/NLPcourse/report/blob/main/Week%2013/AI%20models%20collapse%20when%20trained%20on%20recursively%20generated%20data.pdf) <br> [\[2\]LARGE LANGUAGE MODELS CAN SELF-IMPROVE in Long-context reasoning](https://github.com/NLPcourse/report/blob/main/Week%2013/LARGE%20LANGUAGE%20MODELS%20CAN%20SELF-IMPROVE%20in%20Long-context%20reasoning.pdf) <br> [\[3\]TTRL Test-Time Reinforcement Learning](https://github.com/NLPcourse/report/blob/main/Week%2013/TTRL%20Test-Time%20Reinforcement%20Learning.pdf) <br> | [slide](https://github.com/NLPcourse/report/blob/main/Week%2013/TTRL.pptx) |
| 14 | 5.21 | leave |  |  |
| 15 | 5.28 | 吕瑞森 | [\[1\]Absolute Zero Reinforced Self-play Reasoning with Zero Data](https://github.com/NLPcourse/report/blob/main/Week15/Absolute%20Zero%20Reinforced%20Self-play%20Reasoning%20with%20Zero%20Data.pdf) <br> [\[2\]Executable Code Actions Elicit Better LLM Agents](https://github.com/NLPcourse/report/blob/main/Week15/Executable%20Code%20Actions%20Elicit%20Better%20LLM%20Agents.pdf) | [slide](https://github.com/NLPcourse/report/blob/main/Week15/Absolute%20Zero.pptx) |
| 16 | 6.3 | 吕瑞森 <br> 韩光辉 | [\[1\]ToolHop A Query-Driven Benchmark for Evaluating Large Language Models in Multi-Hop Tool Use.](https://github.com/NLPcourse/report/blob/main/Week16/ToolHop%20A%20Query-Driven%20Benchmark%20for%20Evaluating%20Large%20Language%20Models%20in%20Multi-Hop%20Tool%20Use.pdf) <br> [\[2\]Zero-Shot Multi-Hop Question Answering via Monte-Carlo Tree Search with Large Language Models](https://github.com/NLPcourse/report/blob/main/Week16/2409.19382v2.pdf) <br> [[\[3\]]Answering Questions by Meta-Reasoning over Multiple Chains of Thought](https://github.com/NLPcourse/report/blob/main/Week16/2304.13007v4.pdf) | [slide1](https://github.com/NLPcourse/report/blob/main/Week16/ToolHop.pptx) <br> [slide2](https://github.com/NLPcourse/report/blob/main/Week16/2025%E5%B9%B46%E6%9C%883%E6%97%A5.pptx) |
