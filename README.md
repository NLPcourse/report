# report

| Week | Date | Speaker | Paper | Materials |
| ---- | ---- | ------- | ----- | --------- |
| 1-3 | 2.19 2.26 2.5 | 吕瑞森 | [Better & Faster Large Language Models via Multi-token Prediction](https://github.com/NLPcourse/report/blob/main/Week1-3/Better%20%26%20Faster%20Large%20Language%20Models%20via%20Multi-token%20Prediction.pdf) <br> [DeepSeek-V3 Technical Report](https://github.com/NLPcourse/report/blob/main/Week1-3/DeepSeek-V3%20Technical%20Report.pdf) <br> [EAGLE Speculative Sampling Requires Rethinking Feature Uncertainty](https://github.com/NLPcourse/report/blob/main/Week1-3/EAGLE%20Speculative%20Sampling%20Requires%20Rethinking%20Feature%20Uncertainty.pdf) <br> [Fast Inference from Transformers via Speculative Decoding](https://github.com/NLPcourse/report/blob/main/Week1-3/Fast%20Inference%20from%20Transformers%20via%20Speculative%20Decoding.pdf) <br> [GShard Scaling Giant Models with Conditional Computation and Automatic Sharding](https://github.com/NLPcourse/report/blob/main/Week1-3/GShard%20Scaling%20Giant%20Models%20with%20Conditional%20Computation%20and%20Automatic%20Sharding.pdf) <br> [Switch Transformers Scaling to Trillion Parameter Models with Simple and Efficient Sparsity](https://github.com/NLPcourse/report/blob/main/Week1-3/Switch%20Transformers%20Scaling%20to%20Trillion%20Parameter%20Models%20with%20Simple%20and%20Efficient%20Sparsity.pdf)| [slide]([https://github.com/NLPcourse/report/tree/main/Week1-3](https://github.com/NLPcourse/report/blob/main/Week1-3/DeepSeek-v3.pptx))
